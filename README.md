# clonewars

The purpose of Clonewars is to provide an internal website/service you can run
to simplify the process of getting data from flat files into Redshift.

I wrote this, because the process for getting a non-technical person's data into
Redshift via a COPY command is as follows:

* Explain how COPY works and hope they read all of the documentation on options.
* Get them access to AWS S3.
* Teach them how to use S3.

Clonewars simplifies all three.

## Usage

Clonewars is written in CoffeeScript using [Meteor](http://meteor.com). Get
meteor by following the instructions on the website, then clone this repository.
In `settings.json`, put something like this:

```json
{
  "AWSAccessKeyId": "key",
  "AWSSecretAccessKey": "secret",
  "AWSReadRoleArn": "arn:aws:iam::account_id:role/CloneWarsReadAccess",

  "public": {
    "bucket": "clonewarsfiles"
  },

  "PG": {
    "url": "db.mydb.com/db"
  }
}
```

The key and secret you use should belong to an application-specific user that
only has S3 access to read and write to the bucket you specify here. The read
role is meant to be an IAM role that has read only access to the s3 bucket and
will be used to generate temporary credentials for COPY commands.

You can run the server for development like so:

```
$ meteor --settings settings.json
```

Then you can access the server at localhost:3000.

## How It Works

When you go to the website you'll find a login form asking for your Redshift
username and password. This is because Clonewars just checks that the user
authenticates with Redshift. This works because of [a postgres meteor accounts
adapter](https://github.com/Raynes/meteor-accounts-pg) that I wrote. Makes it
really easy to get your Redshift users in.

Users are allowed to upload files to S3 using the credentials you configured,
and each username gets its own directory in the bucket. The user gets a list of
files with their sizes.

Users can click on a file and they'll see a pop up. This is a COPY command
builder form. Each Redshift option is covered, doc popovers included, and the
copy command is generated from your options. Next iteration will regenerate the
copy command for each change you make automatically.

The resulting COPY command will use credentials generated by assuming an IAM
role that ideally has read only access to the s3 files.

## Deploying

TODO after I have deployed.

## Screenshots

Here's a few screenshots to give you an idea of how it looks.

![](https://dl.dropboxusercontent.com/s/wi45mlnuobj3aqx/2015-01-07%20at%2011.46%20PM%202x.png?dl=0)
![](https://dl.dropboxusercontent.com/s/z5ljgxnm88nv5nw/2015-01-07%20at%2011.46%20PM%202x%20%281%29.png?dl=0)

The doc popovers on each label:

![](https://dl.dropboxusercontent.com/s/ew5jw5pv846nqq2/2015-01-07%20at%2011.51%20PM%202x.png?dl=0)
